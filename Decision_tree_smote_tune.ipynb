{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d36d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da800089",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144a12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_to_try = ['utf-8-sig', 'latin-1', 'ISO-8859-1']\n",
    "\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        df = pd.read_csv(\"C:/Users/15694/Desktop/Cross selling/code/Michelle/variable_without_pca2.csv\", encoding=encoding)\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ff191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a049c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c602b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a566fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6fce958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[[\"TOTAL_AVG_BAL\",\"SIX_MONTH_BAL_OS_FD\",\"SIX_MONTH_BAL_OS_SAVINGS\",\"CUSTOMER_PROFITABILITY\"\n",
    "        ,\"LOAN_CAT1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230a2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=[\"LOAN_CAT1\"])\n",
    "Y = df1[\"LOAN_CAT1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c19cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score,  classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97cd023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b8d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from collections import Counter\n",
    "sm = SMOTE()\n",
    "X_sm, Y_sm=sm.fit_resample(X_train,y_train)\n",
    "print('Dataset after resampling:')\n",
    "print(sorted(Counter(Y_sm).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd60d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfdbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f29e470f",
   "metadata": {},
   "source": [
    "### Tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c8686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09cc8809",
   "metadata": {},
   "source": [
    "###### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e46dd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f895c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=0)\n",
    "decision_tree.fit(X_sm, Y_sm)\n",
    "y_pred_DT = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717a1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_DT)\n",
    "prec_macro = precision_score(y_test, y_pred_DT, average='macro')\n",
    "recall_macro = recall_score(y_test, y_pred_DT, average='macro')\n",
    "f1_macro = f1_score(y_test, y_pred_DT, average='macro')\n",
    "classification_rep = classification_report(y_test, y_pred_DT)\n",
    "print(\"Accuracy Score:\", acc)\n",
    "print(\"Precision (Macro):\", prec_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred_DT)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5a89775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_train_DT = decision_tree.predict(X_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94685302",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_sm, y_pred_train_DT)\n",
    "prec_macro = precision_score(Y_sm, y_pred_train_DT, average='macro')\n",
    "recall_macro = recall_score(Y_sm, y_pred_train_DT, average='macro')\n",
    "f1_macro = f1_score(Y_sm, y_pred_train_DT, average='macro')\n",
    "classification_rep_DT = classification_report(Y_sm,y_pred_train_DT)\n",
    "print(\"Accuracy Score:\", acc)\n",
    "print(\"Precision (Macro):\", prec_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix_DT = confusion_matrix(Y_sm, y_pred_train_DT)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cf_matrix_DT)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5144e5",
   "metadata": {},
   "source": [
    "##### pre pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd4bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c41ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'max_depth': range(2,50,1),\n",
    "         'min_samples_split': range(1,5,1),\n",
    "         'min_samples_leaf': range(2,5,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfe17ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(random_state=0)\n",
    "grid_search = GridSearchCV(dtree, param_grid, cv=5)\n",
    "grid_search.fit(X_sm, Y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73ee652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c16cf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtree_pp = DecisionTreeClassifier(max_depth=17, min_samples_leaf=2, min_samples_split=2)\n",
    "best_dtree_pp.fit(X_sm, Y_sm)\n",
    "y_pred_pre = best_dtree_pp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4621c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_pre)\n",
    "prec_macro = precision_score(y_test, y_pred_pre, average='macro')\n",
    "recall_macro = recall_score(y_test, y_pred_pre, average='macro')\n",
    "f1_macro = f1_score(y_test, y_pred_pre, average='macro')\n",
    "classification_rep_pre = classification_report(y_test, y_pred_pre)\n",
    "print(\"Accuracy Score:\", acc)\n",
    "print(\"Precision (Macro):\", prec_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix_pre = confusion_matrix(y_test, y_pred_pre)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cf_matrix_pre)\n",
    "print(\"\\n Test Classification Report:\\n\", classification_rep_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a39f34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pre_train = best_dtree_pp.predict(X_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2eecab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_sm, y_pred_pre_train )\n",
    "prec_macro = precision_score(Y_sm, y_pred_pre_train , average='macro')\n",
    "recall_macro = recall_score(Y_sm, y_pred_pre_train, average='macro')\n",
    "f1_macro = f1_score(Y_sm, y_pred_pre_train , average='macro')\n",
    "classification_rep_pre_train = classification_report(Y_sm,y_pred_pre_train)\n",
    "print(\"Accuracy Score:\", acc)\n",
    "print(\"Precision (Macro):\", prec_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix_DT_pre = confusion_matrix(Y_sm, y_pred_pre_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cf_matrix_DT_pre)\n",
    "print(\"\\n Train Classification Report:\\n\", classification_rep_pre_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461caa2",
   "metadata": {},
   "source": [
    "#### post pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88013409",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "effbd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = decision_tree.cost_complexity_pruning_path(X_sm, Y_sm)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "print(ccp_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6688669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each alpha we will append our model to a list\n",
    "decision_trees = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    decision_tree = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    decision_tree.fit(X_sm, Y_sm)\n",
    "    decision_trees.append(decision_tree)\n",
    "print(\"Number of nodes in the last tree is :{} with ccp_alpha:{}\".format(\n",
    "decision_trees[-1].tree_.node_count,ccp_alphas[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61aabd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores=[decision_tree.score(X_sm, Y_sm) for decision_tree in decision_trees]\n",
    "test_scores=[decision_tree.score(X_test, y_test) for decision_tree in decision_trees]\n",
    "\n",
    "fig,ax =plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing data sets\")\n",
    "ax.plot(ccp_alphas,train_scores,marker='o',label=\"train\",drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas,test_scores,marker='o',label=\"test\",drawstyle=\"steps-post\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdbce255",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = tree.DecisionTreeClassifier(random_state=0,ccp_alpha=0.001)\n",
    "decision_tree.fit(X_sm, Y_sm)\n",
    "\n",
    "y_train_pred_po = decision_tree.predict(X_sm)\n",
    "y_test_pred_po = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9666f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_test_pred_po)\n",
    "prec_macro = precision_score(y_test, y_test_pred_po, average='macro')\n",
    "recall_macro = recall_score(y_test, y_test_pred_po, average='macro')\n",
    "f1_macro = f1_score(y_test, y_test_pred_po, average='macro')\n",
    "classification_rep_po = classification_report(y_test, y_test_pred_po)\n",
    "print(\"Accuracy Score:\", acc)\n",
    "print(\"Precision (Macro):\", prec_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix_po= confusion_matrix(y_test, y_test_pred_po)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cf_matrix_po)\n",
    "print(\"\\n Test Classification Report:\\n\", classification_rep_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2089328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_sm, y_train_pred_po )\n",
    "prec_macro = precision_score(Y_sm, y_train_pred_po , average='macro')\n",
    "recall_macro = recall_score(Y_sm, y_train_pred_po, average='macro')\n",
    "f1_macro = f1_score(Y_sm, y_train_pred_po , average='macro')\n",
    "classification_rep_DT_po = classification_report(Y_sm,y_train_pred_po )\n",
    "print(\"Accuracy Score:\", acc)\n",
    "print(\"Precision (Macro):\", prec_macro)\n",
    "print(\"Recall (Macro):\", recall_macro)\n",
    "print(\"F1 Score (Macro):\", f1_macro)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix_po = confusion_matrix(Y_sm, y_train_pred_po)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cf_matrix_po)\n",
    "print(\"\\n Train Classification Report:\\n\", classification_rep_DT_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86a0485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4f3d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob=decision_tree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0b8525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(np.unique(Y))):\n",
    "    fpt,tpr,_=roc_curve(y_test==i,y_prob[:,i])\n",
    "    roc_auc=auc(fpt,tpr)\n",
    "    plt.plot(fpt,tpr,label=f'Class {i} Vs Rest (AUC ={roc_auc:.2f})')\n",
    "    \n",
    "plt.plot([0,1],[0,1],linestyle='--',color='r',label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Multi-class Classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7099f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_prob,multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69286ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
